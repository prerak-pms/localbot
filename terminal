<<<<<<< HEAD
# making the directory

cd "C:\Users\shahp\Documents\Coding"

# making the project folder
mkdir "local-llm-project"  
cd "local-llm-project"

# creating new environment
python -m venv venv
.\venv\Scripts\Activate

# installing environment
winget install Ollama.Ollama

# pulling a light weight model
ollama pull mistral

# This will allow us to process PDFs, text files, and other documents for querying.
pip install llama-index llama-index-llms-ollama 
pip install llama-index-embeddings-ollama
pip install llama-index-embeddings-openai
pip install llama-index-core
pip install llama-index-embeddings-huggingface